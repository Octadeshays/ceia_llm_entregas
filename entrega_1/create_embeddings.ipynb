{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import PINECONE, GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: octavio_cv.odt\n",
      "Contenido (primeros 100 caracteres): \n",
      "Octavio Deshays\n",
      "Mechatronics Engineer - National University of Cuyo\n",
      "Mendoza, Argentina\n",
      "22/12/1997\n",
      "+\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from odf.opendocument import load\n",
    "from odf.text import P\n",
    "\n",
    "def leer_documentos_odt(carpeta):\n",
    "    \"\"\"\n",
    "    Lee todos los archivos .odt en una carpeta y devuelve un diccionario con el contenido.\n",
    "\n",
    "    Args:\n",
    "        carpeta (str): Ruta a la carpeta que contiene los archivos .odt.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario donde las claves son los nombres de los archivos y los valores son los contenidos de los textos.\n",
    "    \"\"\"\n",
    "    documentos = {}\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        if archivo.endswith(\".odt\"):  # Verifica que el archivo sea .odt\n",
    "            ruta_archivo = os.path.join(carpeta, archivo)\n",
    "            # Cargar el archivo .odt\n",
    "            documento = load(ruta_archivo)\n",
    "            contenido = []\n",
    "            # Extraer el texto de los párrafos\n",
    "            for elemento in documento.getElementsByType(P):\n",
    "                contenido.append(str(elemento))\n",
    "            documentos[archivo] = \"\\n\".join(contenido)\n",
    "    return documentos\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "carpeta = \"docs/\"  # Reemplaza con la ruta de tu carpeta\n",
    "full_documents = leer_documentos_odt(carpeta)\n",
    "\n",
    "# Mostrar el nombre y una muestra de los documentos leídos\n",
    "for nombre, contenido in full_documents.items():\n",
    "    print(f\"Archivo: {nombre}\")\n",
    "    print(f\"Contenido (primeros 100 caracteres): {contenido[:100]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'octavio_cv.odt': \"\\nOctavio Deshays\\nMechatronics Engineer - National University of Cuyo\\nMendoza, Argentina\\n22/12/1997\\n+54 9 2615538396\\noctaviodeshays@gmail.com\\nln: Octavio Deshays Moreno\\nEXPERIENCE\\nMARVIK, Uruguay — Machine Learning Engineer\\nDecember 2022 - Present\\nMarvik is a hands-on ML consulting firm. In my role, I am involved in the entire process of developing an AI solution, from identifying the customer's problem to implementing the solution.\\nProjects: \\nPhotoStudio Editor: an app to allow sellers from the largest E-Commerce in LatinAmerica to edit their products images using Stable Diffusion, generating attractive backgrounds for each product. Currently in production being used by thousands of users every hour.\\nFashion Recommendation System: designed and built MVP for a Tinder like recsys for a fashion company. Involved building a feature extraction pipeline for garments using CLIP based classifiers and a Reinforcement Learning algorithm.\\nVirtual Try On: for this project, I worked in both image processor and Diffusion pipeline used to generate a Try On\\nConveyor Belt Control: Utilized computer vision to monitor the entry of wooden logs into machinery in a paper mill. Involved the use of a Jetson device, frame processing, and the development of a control algorithm based on outputs from AI models.\\nUsed technologies: \\nMultimodal Neural Networks, CNN, Classification models, Image Segmentation, Image Enhancement, Stable Diffusion, Data Extraction pipelines. \\nRecommendation Systems, Clustering, Reinforcement Learning. \\nPython, Docker, Fast API, AWS: EC2, S3. \\nDEEP AGRO, Argentina — Machine Learning Engineer\\nMarch 2021 - November 2022\\nDeepAgro is an agtech start up with the mission of creating a brighter future for Agriculture by using innovation and Artificial Intelligence. I was in charge of developing, testing, maintaining and deploying production ready computer vision models on edge devices. \\n\\nUsed technologies:\\n- Convolutional Neural Networks, YOLO, Generative Adversarial Networks, Decision Trees, Random Forest, Image classification, Object Tracking.\\n- Pytorch, TensorFlow, Darknet, ScikitLearn, TensorRT , OpenCV, Google Data Studio.\\n- Python, C++, linux.\\nINCA JUNIOR ENTERPRISE, Argentina — Innovation and Development Department Coordinator\\nJanuary 2021 - January 2021\\nINCA JE is a Non-profit organization that seeks to strengthen university education, linking students with small companies.\\nIntroduction to Python Course: design and delivery of introductory course for university students\\nPitching Ideas: design and delivery of a Pitching workshop.\\nNational University of Cuyo, Argentina— Teacher Assistant\\nMarch 2018 - March 2019\\nI assisted students during classes, helping them to solve problems with Analytic Geometry. \\n\\n\\nEDUCATION\\nUniversity of Buenos Aires, Argentina — Post Graduate Specialization in Artificial Intelligence \\nPost graduate university degree in Artificial Intelligence, covering all topics from classic Machine Learning algorithms to Generative AI. \\nAugust 2023 - March 2025\\nNational University of Cuyo, Argentina — Degree in Mechatronics Engineering\\nMARCH 2016 - MAY 2022\\nUniversity degree in Mechatronics with an average grade of 8.91, which is the best grade of the Mechatronics Class of 2016 and the fourth best among all students in the Engineering School.\\nBest Graduate Mechatronic Engineering class 2022. \\nUniversity Of Alabama, EEUU — Fulbright Scholar\\nAUGUST 2021 - OCTOBER 2021\\nIn December 2020 I was awarded a scholarship called Friends of Fulbright, which is given by the Argentine Fulbright Commission and it is sponsored by the US Embassy. Thanks to this, I spent two months at the University of Alabama, where I was able to take the following courses: \\nComputational Intelligence\\nIntro to Autonomous Robotics\\nIdentifying and Pitching Opportunities\\nAdvanced English Language Classes. \\nPROJECTS\\nTo infinity and Beyond — Digital Twin Development\\nWinning team of the Open Space contest that launched an experiment into space in one of the satellites of the company Satellogic. \\nMy job consisted of the development of Artificial Intelligence Models for Satellite Temperature Prediction and Cloud Segmentation together with a WebbApp that allows users to interact with the Satellite Data. All this work was also part of my Mechatronics Engineering Final Project, which can be seen here. Thanks to my work on this project, I can proudly say that my name is in space!\\nAWARDS\\nMember of the National Flag honor group. Honor I received for having the fourth best Grade rate of the 2016 Engineering School Class. (certification)\\nBest Graduate Mechatronic Engineering class 2022. \\nVolunteering\\nEmpate Foundation. Futbol Coach for young adults with Down Syndrome. \\nLANGUAGES\\nEnglish - C1 level TOEFL iBT 104/120\\n\\n\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'octavio_cv.odt'}, page_content=\"Octavio Deshays\\nMechatronics Engineer - National University of Cuyo\\nMendoza, Argentina\\n22/12/1997\\n+54 9 2615538396\\noctaviodeshays@gmail.com\\nln: Octavio Deshays Moreno\\nEXPERIENCE\\nMARVIK, Uruguay — Machine Learning Engineer\\nDecember 2022 - Present\\nMarvik is a hands-on ML consulting firm. In my role, I am involved in the entire process of developing an AI solution, from identifying the customer's problem to implementing the solution.\\nProjects: \\nPhotoStudio Editor: an app to allow sellers from the largest E-Commerce in LatinAmerica to edit their products images using Stable Diffusion, generating attractive backgrounds for each product. Currently in production being used by thousands of users every hour.\\nFashion Recommendation System: designed and built MVP for a Tinder like recsys for a fashion company. Involved building a feature extraction pipeline for garments using CLIP based classifiers and a Reinforcement Learning algorithm.\"),\n",
       " Document(metadata={'source': 'octavio_cv.odt'}, page_content='Virtual Try On: for this project, I worked in both image processor and Diffusion pipeline used to generate a Try On\\nConveyor Belt Control: Utilized computer vision to monitor the entry of wooden logs into machinery in a paper mill. Involved the use of a Jetson device, frame processing, and the development of a control algorithm based on outputs from AI models.\\nUsed technologies: \\nMultimodal Neural Networks, CNN, Classification models, Image Segmentation, Image Enhancement, Stable Diffusion, Data Extraction pipelines. \\nRecommendation Systems, Clustering, Reinforcement Learning. \\nPython, Docker, Fast API, AWS: EC2, S3. \\nDEEP AGRO, Argentina — Machine Learning Engineer\\nMarch 2021 - November 2022\\nDeepAgro is an agtech start up with the mission of creating a brighter future for Agriculture by using innovation and Artificial Intelligence. I was in charge of developing, testing, maintaining and deploying production ready computer vision models on edge devices.'),\n",
       " Document(metadata={'source': 'octavio_cv.odt'}, page_content='Used technologies:\\n- Convolutional Neural Networks, YOLO, Generative Adversarial Networks, Decision Trees, Random Forest, Image classification, Object Tracking.\\n- Pytorch, TensorFlow, Darknet, ScikitLearn, TensorRT , OpenCV, Google Data Studio.\\n- Python, C++, linux.\\nINCA JUNIOR ENTERPRISE, Argentina — Innovation and Development Department Coordinator\\nJanuary 2021 - January 2021\\nINCA JE is a Non-profit organization that seeks to strengthen university education, linking students with small companies.\\nIntroduction to Python Course: design and delivery of introductory course for university students\\nPitching Ideas: design and delivery of a Pitching workshop.\\nNational University of Cuyo, Argentina— Teacher Assistant\\nMarch 2018 - March 2019\\nI assisted students during classes, helping them to solve problems with Analytic Geometry.'),\n",
       " Document(metadata={'source': 'octavio_cv.odt'}, page_content='EDUCATION\\nUniversity of Buenos Aires, Argentina — Post Graduate Specialization in Artificial Intelligence \\nPost graduate university degree in Artificial Intelligence, covering all topics from classic Machine Learning algorithms to Generative AI. \\nAugust 2023 - March 2025\\nNational University of Cuyo, Argentina — Degree in Mechatronics Engineering\\nMARCH 2016 - MAY 2022\\nUniversity degree in Mechatronics with an average grade of 8.91, which is the best grade of the Mechatronics Class of 2016 and the fourth best among all students in the Engineering School.\\nBest Graduate Mechatronic Engineering class 2022. \\nUniversity Of Alabama, EEUU — Fulbright Scholar\\nAUGUST 2021 - OCTOBER 2021\\nIn December 2020 I was awarded a scholarship called Friends of Fulbright, which is given by the Argentine Fulbright Commission and it is sponsored by the US Embassy. Thanks to this, I spent two months at the University of Alabama, where I was able to take the following courses: \\nComputational Intelligence'),\n",
       " Document(metadata={'source': 'octavio_cv.odt'}, page_content='Computational Intelligence\\nIntro to Autonomous Robotics\\nIdentifying and Pitching Opportunities\\nAdvanced English Language Classes. \\nPROJECTS\\nTo infinity and Beyond — Digital Twin Development\\nWinning team of the Open Space contest that launched an experiment into space in one of the satellites of the company Satellogic. \\nMy job consisted of the development of Artificial Intelligence Models for Satellite Temperature Prediction and Cloud Segmentation together with a WebbApp that allows users to interact with the Satellite Data. All this work was also part of my Mechatronics Engineering Final Project, which can be seen here. Thanks to my work on this project, I can proudly say that my name is in space!\\nAWARDS\\nMember of the National Flag honor group. Honor I received for having the fourth best Grade rate of the 2016 Engineering School Class. (certification)\\nBest Graduate Mechatronic Engineering class 2022. \\nVolunteering\\nEmpate Foundation. Futbol Coach for young adults with Down Syndrome.'),\n",
       " Document(metadata={'source': 'octavio_cv.odt'}, page_content='LANGUAGES\\nEnglish - C1 level TOEFL iBT 104/120')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def chunk_data(docs, chunk_size=800, chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return doc\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=contenido, metadata={\"source\": nombre})\n",
    "    for nombre, contenido in full_documents.items()\n",
    "]\n",
    "\n",
    "documents=chunk_data(docs=docs,chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7765/510785800.py:14: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/POSTGRADO_IA/LLMs/ceia_llm_entregas/.venv/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:84\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m [embeddings_model\u001b[38;5;241m.\u001b[39membed_query(chunk\u001b[38;5;241m.\u001b[39mpage_content) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n\u001b[0;32m---> 18\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mgenerar_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m embeddings\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36mgenerar_embeddings\u001b[0;34m(chunks, model_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerar_embeddings\u001b[39m(chunks, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    Genera embeddings para cada chunk usando un modelo HuggingFace.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m        list: Lista de embeddings.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     embeddings_model \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m [embeddings_model\u001b[38;5;241m.\u001b[39membed_query(chunk\u001b[38;5;241m.\u001b[39mpage_content) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/POSTGRADO_IA/LLMs/ceia_llm_entregas/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     emit_warning()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/POSTGRADO_IA/LLMs/ceia_llm_entregas/.venv/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py:87\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m     94\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def generar_embeddings(chunks, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Genera embeddings para cada chunk usando un modelo HuggingFace.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): Lista de chunks de texto.\n",
    "        model_name (str): Nombre del modelo HuggingFace (puedes usar uno compatible con Groq).\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de embeddings.\n",
    "    \"\"\"\n",
    "    embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    embeddings = [embeddings_model.embed_query(chunk.page_content) for chunk in chunks]\n",
    "    return embeddings\n",
    "\n",
    "embeddings = generar_embeddings(documents)\n",
    "\n",
    "embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings with pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(PINECONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octadesh/POSTGRADO_IA/LLMs/ceia_llm_entregas/.venv/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingsList(\n",
      "  model='multilingual-e5-large',\n",
      "  vector_type='dense',\n",
      "  data=[\n",
      "    {'vector_type': dense, 'values': [0.031158447265625, -0.016265869140625, ..., -0.0426025390625, -0.01401519775390625]},\n",
      "    {'vector_type': dense, 'values': [0.002185821533203125, -0.040802001953125, ..., -0.0263671875, -0.00390625]},\n",
      "    ... (2 more embeddings) ...,\n",
      "    {'vector_type': dense, 'values': [0.012176513671875, -0.029937744140625, ..., -0.01898193359375, -0.0016937255859375]},\n",
      "    {'vector_type': dense, 'values': [0.0273590087890625, -0.02130126953125, ..., -0.0164031982421875, -0.0007061958312988281]}\n",
      "  ],\n",
      "  usage={'total_tokens': 1097}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a Pinecone client with your API key\n",
    "pc = Pinecone(api_key=PINECONE)\n",
    "\n",
    "# Define a sample dataset where each item has a unique ID and piece of text\n",
    "data = [{\"id\": f\"vec{i+1}\", \"text\": doc.page_content} for i, doc in enumerate(documents)]\n",
    "\n",
    "# Convert the text into numerical vectors that Pinecone can index\n",
    "embeddings = pc.inference.embed(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    inputs=[d['text'] for d in data],\n",
    "    parameters={\"input_type\": \"passage\", \"truncate\": \"END\"}\n",
    ")\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.data[0]['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a serverless index\n",
    "index_name = \"example-index\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=len(embeddings.data[0]['values']),\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) \n",
    "\n",
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example-index']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 6}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(\"example-index\")\n",
    "\n",
    "# Prepare the records for upsert\n",
    "# Each contains an 'id', the embedding 'values', and the original text as 'metadata'\n",
    "records = []\n",
    "for d, e in zip(data, embeddings):\n",
    "    records.append({\n",
    "        \"id\": d['id'],\n",
    "        \"values\": e['values'],\n",
    "        \"metadata\": {'text': d['text']}\n",
    "    })\n",
    "\n",
    "# Upsert the records into the index\n",
    "index.upsert(\n",
    "    vectors=records,\n",
    "    namespace=\"example-namespace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'example-namespace': {'vector_count': 6}},\n",
      " 'total_vector_count': 6}\n"
     ]
    }
   ],
   "source": [
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': 'vec1',\n",
      "              'metadata': {'text': 'Octavio Deshays\\n'\n",
      "                                   'Mechatronics Engineer - National '\n",
      "                                   'University of Cuyo\\n'\n",
      "                                   'Mendoza, Argentina\\n'\n",
      "                                   '22/12/1997\\n'\n",
      "                                   '+54 9 2615538396\\n'\n",
      "                                   'octaviodeshays@gmail.com\\n'\n",
      "                                   'ln: Octavio Deshays Moreno\\n'\n",
      "                                   'EXPERIENCE\\n'\n",
      "                                   'MARVIK, Uruguay — Machine Learning '\n",
      "                                   'Engineer\\n'\n",
      "                                   'December 2022 - Present\\n'\n",
      "                                   'Marvik is a hands-on ML consulting firm. '\n",
      "                                   'In my role, I am involved in the entire '\n",
      "                                   'process of developing an AI solution, from '\n",
      "                                   \"identifying the customer's problem to \"\n",
      "                                   'implementing the solution.\\n'\n",
      "                                   'Projects: \\n'\n",
      "                                   'PhotoStudio Editor: an app to allow '\n",
      "                                   'sellers from the largest E-Commerce in '\n",
      "                                   'LatinAmerica to edit their products images '\n",
      "                                   'using Stable Diffusion, generating '\n",
      "                                   'attractive backgrounds for each product. '\n",
      "                                   'Currently in production being used by '\n",
      "                                   'thousands of users every hour.\\n'\n",
      "                                   'Fashion Recommendation System: designed '\n",
      "                                   'and built MVP for a Tinder like recsys for '\n",
      "                                   'a fashion company. Involved building a '\n",
      "                                   'feature extraction pipeline for garments '\n",
      "                                   'using CLIP based classifiers and a '\n",
      "                                   'Reinforcement Learning algorithm.'},\n",
      "              'score': 0.814608216,\n",
      "              'values': []}],\n",
      " 'namespace': 'example-namespace',\n",
      " 'usage': {'read_units': 6}}\n"
     ]
    }
   ],
   "source": [
    "# Define your query\n",
    "query = \"work in marvik\"\n",
    "\n",
    "# Convert the query into a numerical vector that Pinecone can search with\n",
    "query_embedding = pc.inference.embed(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    inputs=[query],\n",
    "    parameters={\n",
    "        \"input_type\": \"query\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Search the index for the three most similar vectors\n",
    "results = index.query(\n",
    "    namespace=\"example-namespace\",\n",
    "    vector=query_embedding[0].values,\n",
    "    top_k=1,\n",
    "    include_values=False,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
